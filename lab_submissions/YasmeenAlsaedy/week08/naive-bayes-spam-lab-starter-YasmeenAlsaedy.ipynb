{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png\" style=\"float: left; margin: 15px;\">\n",
    "\n",
    "## Naive Bayes Spam Filter Using SpamAssassin Data\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "In this lab, we will write our own spam filter -- one of the many practical uses of Naive Bayes. We will additionally explore methods for visualizing text features in an effort to gain insight and improve our models.\n",
    "\n",
    "### Background\n",
    "\n",
    "The statistical approach for classifying spam was championed by Paul Graham, founder of Y Combinator. We highly recommend you read his classic (and very readable!) essay [A Plan for Spam](http://www.paulgraham.com/spam.html) to gain insight into why Naive Bayes works so well with spam.\n",
    "\n",
    "The reason why Naive Bayes works incredibly well to classify spam is because spam aligns with the independence assumption. Certain keywords in emails -- taken by themselves (e.g. Nigeria / prince) -- typically indicate a spam message.\n",
    "\n",
    "In this lab, the word **ham** indicates an email message that was authorized by the user. Sometimes we receive advertising emails that look like spam, yet we agreed to receive them. This fact can make spam detection more difficult. For a challenge, try classifying the `hard_ham` dataset below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1. Download the data\n",
    "\n",
    "We are using the data files from the SpamAssassin dataset:\n",
    "\n",
    "+ https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2\n",
    "+ https://spamassassin.apache.org/old/publiccorpus/20021010_hard_ham.tar.bz2\n",
    "+ https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2\n",
    "\n",
    "From the command line, you can either use ```curl``` to download into the current directory. For an example of each:\n",
    "\n",
    "    curl http://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2 > 20021010_easy_ham.tar.bz2\n",
    "\n",
    "You can use ```tar xvf <file>``` to extract into the current directory (x - extract, v - verbose, f - read from file). For example:\n",
    "\n",
    "    tar xvf 20021010_easy_ham.tar.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get directory contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./datasets/spam/0355.94ebf637e4bd3db8a81c8ce68ecf681d',\n",
       " './datasets/spam/0395.bb934e8b4c39d5eab38f828a26f760b4',\n",
       " './datasets/spam/0485.9021367278833179285091e5201f5854',\n",
       " './datasets/spam/0343.0630afbe4ee1ffd0db0ffb81c6de98de',\n",
       " './datasets/spam/0125.44381546181fc6c5d7ea59e917f232c5',\n",
       " './datasets/spam/0108.4506c2ef846b80b9a7beb90315b22701',\n",
       " './datasets/spam/0112.ec411d26d1f4decc16af7ef73e69a227',\n",
       " './datasets/spam/0060.140f80780520fa19b360ddcb05838a67',\n",
       " './datasets/spam/0392.9e194dfff92f7d9957171b04a8d4b957',\n",
       " './datasets/spam/0441.b820c1999715c2e5ded6418d2b17723c']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: Ensure base_dir points to the base directory where you extracted your data files!\n",
    "#   Inside this directory should be three folders -- easy_ham, hard_ham, and spam.\n",
    "\n",
    "base_dir = './datasets'\n",
    "easy_ham_files = glob.glob(base_dir + \"/easy_ham/*\")\n",
    "hard_ham_files = glob.glob(base_dir + \"/hard_ham/*\")\n",
    "spam_files = glob.glob(base_dir + \"/spam/*\")\n",
    "spam_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From rssfeeds@jmason.org  Mon Sep 30 13:43:46 2002\n",
      "Return-Path: <rssfeeds@example.com>\n",
      "Delivered-To: yyyy@localhost.example.com\n",
      "Received: from localhost (jalapeno [127.0.0.1])\n",
      "\tby jmason.org (Postfix) with ESMTP id AE79816F16\n",
      "\tfor <jm@localhost>; Mon, 30 Sep 2002 13:43:46 +0100 (IST)\n",
      "Received: from jalapeno [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor jm@localhost (single-drop); Mon, 30 Sep 2002 13:43:46 +0100 (IST)\n",
      "Received: from dogma.slashnull.org (localhost [127.0.0.1]) by\n",
      "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g8U81fg21359 for\n",
      "    <jm@jmason.org>; Mon, 30 Sep 2002 09:01:41 +0100\n",
      "Message-Id: <200209300801.g8U81fg21359@dogma.slashnull.org>\n",
      "To: yyyy@example.com\n",
      "From: gamasutra <rssfeeds@example.com>\n",
      "Subject: Priceless Rubens works stolen in raid on mansion\n",
      "Date: Mon, 30 Sep 2002 08:01:41 -0000\n",
      "Content-Type: text/plain; encoding=utf-8\n",
      "Lines: 6\n",
      "X-Spam-Status: No, hits=-527.4 required=5.0\n",
      "\ttests=AWL,DATE_IN_PAST_03_06,T_URI_COUNT_0_1\n",
      "\tversion=2.50-cvs\n",
      "X-Spam-Level: \n",
      "\n",
      "URL: http://www.newsisfree.com/click/-1,8381145,215/\n",
      "Date: 2002-09-30T03:04:58+01:00\n",
      "\n",
      "*Arts:* Fourth art raid on philanthropist's home once targeted by the IRA and \n",
      "Dublin gangster Martin Cahill.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use Python 3's open function, which supports the encoding parameter\n",
    "from io import open\n",
    "\n",
    "# Create list of full-text of all ham and spam emails\n",
    "\n",
    "# read the easy ham files into a list\n",
    "easy_ham_text = []\n",
    "for filename in easy_ham_files:\n",
    "    with open(filename, 'r', encoding='iso-8859-15') as f:\n",
    "        easy_ham_text.append(f.read())\n",
    "\n",
    "# read the easy ham files into a list\n",
    "hard_ham_text = []\n",
    "for filename in hard_ham_files:\n",
    "    with open(filename, 'r', encoding='iso-8859-15') as f:\n",
    "        hard_ham_text.append(f.read())\n",
    "        \n",
    "# read the spam files into a list\n",
    "spam_text = []\n",
    "for filename in spam_files:\n",
    "    with open(filename, 'r', encoding='iso-8859-15') as f:\n",
    "        spam_text.append(f.read())\n",
    "\n",
    "print(easy_ham_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's merge all of the emails into a single list of emails -- this is our data!\n",
    "ham_and_spam_text = easy_ham_text + spam_text    # extends the lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467\n",
      "2374\n",
      "2841\n"
     ]
    }
   ],
   "source": [
    "# How imbalanced is our dataset?\n",
    "\n",
    "print(len(spam_text))\n",
    "print(len(easy_ham_text))\n",
    "print(len(ham_and_spam_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Label the data\n",
    "\n",
    "We now have `ham_and_spam_text`, a single list containing our emails. However, now we need this data to be labeled with what we will predict. In this case, we will make a list of 0s and 1s indicating whether each of these emails is ham (0) or spam (1). Can you make this list, given how we combined the spam and ham into one list above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[text,\"1\"] if text in spam_text else [text,\"0\"] for text in ham_and_spam_text],\n",
    "                            columns=[\"text\",\"spam\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From rssfeeds@jmason.org  Mon Sep 30 13:43:46 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From fork-admin@xent.com  Tue Sep  3 14:24:41 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From exmh-users-admin@redhat.com  Wed Sep 11 1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From fork-admin@xent.com  Mon Sep  2 16:22:12 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From rssfeeds@jmason.org  Fri Sep 27 10:40:59 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text spam\n",
       "0  From rssfeeds@jmason.org  Mon Sep 30 13:43:46 ...    0\n",
       "1  From fork-admin@xent.com  Tue Sep  3 14:24:41 ...    0\n",
       "2  From exmh-users-admin@redhat.com  Wed Sep 11 1...    0\n",
       "3  From fork-admin@xent.com  Mon Sep  2 16:22:12 ...    0\n",
       "4  From rssfeeds@jmason.org  Fri Sep 27 10:40:59 ...    0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Transform the emails into features\n",
    " \n",
    "We will be using cross validation later to assess performance, so feel free to fit it on the entire dataset for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.A. Fit the model on your data using `CountVectorizer`\n",
    "\n",
    "Using `CountVectorizer` ONLY, transform each email into features. Consider now or later removing stopwords, trying different ngram sizes, making all words lowercase, and/or creating your own features (e.g. presence of an unsubscribe link!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we are going to create a fct to stemmer the words in the email\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "# Return a callable that handles preprocessing and tokenization\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from rssfeed jmason org mon sep 30 13 43 46 2002 return path rssfeed exampl com deliv to yyyi localhost exampl com receiv from localhost jalapeno 127 by jmason org postfix with esmtp id ae79816f16 for jm localhost mon 30 sep 2002 13 43 46 0100 ist receiv from jalapeno 127 by localhost with imap fetchmail for jm localhost singl drop mon 30 sep 2002 13 43 46 0100 ist receiv from dogma slashnul org localhost 127 by dogma slashnul org 11 11 with esmtp id g8u81fg21359 for jm jmason org mon 30 sep 2002 09 01 41 0100 messag id 200209300801 g8u81fg21359 dogma slashnul org to yyyi exampl com from gamasutra rssfeed exampl com subject priceless ruben work stolen in raid on mansion date mon 30 sep 2002 08 01 41 0000 content type text plain encod utf line spam statu no hit 527 requir test awl date_in_past_03_06 t_uri_count_0_1 version 50 cv spam level url http www newsisfre com click 8381145 215 date 2002 09 30t03 04 58 01 00 art fourth art raid on philanthropist home onc target by the ira and dublin gangster martin cahil\n",
      "\n",
      " From rssfeeds@jmason.org  Mon Sep 30 13:43:46 2002\n",
      "Return-Path: <rssfeeds@example.com>\n",
      "Delivered-To: yyyy@localhost.example.com\n",
      "Received: from localhost (jalapeno [127.0.0.1])\n",
      "\tby jmason.org (Postfix) with ESMTP id AE79816F16\n",
      "\tfor <jm@localhost>; Mon, 30 Sep 2002 13:43:46 +0100 (IST)\n",
      "Received: from jalapeno [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor jm@localhost (single-drop); Mon, 30 Sep 2002 13:43:46 +0100 (IST)\n",
      "Received: from dogma.slashnull.org (localhost [127.0.0.1]) by\n",
      "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g8U81fg21359 for\n",
      "    <jm@jmason.org>; Mon, 30 Sep 2002 09:01:41 +0100\n",
      "Message-Id: <200209300801.g8U81fg21359@dogma.slashnull.org>\n",
      "To: yyyy@example.com\n",
      "From: gamasutra <rssfeeds@example.com>\n",
      "Subject: Priceless Rubens works stolen in raid on mansion\n",
      "Date: Mon, 30 Sep 2002 08:01:41 -0000\n",
      "Content-Type: text/plain; encoding=utf-8\n",
      "Lines: 6\n",
      "X-Spam-Status: No, hits=-527.4 required=5.0\n",
      "\ttests=AWL,DATE_IN_PAST_03_06,T_URI_COUNT_0_1\n",
      "\tversion=2.50-cvs\n",
      "X-Spam-Level: \n",
      "\n",
      "URL: http://www.newsisfree.com/click/-1,8381145,215/\n",
      "Date: 2002-09-30T03:04:58+01:00\n",
      "\n",
      "*Arts:* Fourth art raid on philanthropist's home once targeted by the IRA and \n",
      "Dublin gangster Martin Cahill.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can now apply it using the countvectorizer from sklearn:\n",
    "print(\" \".join(stemmed_words(df.iloc[0,0])))\n",
    "print(\"\\n\",df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "countv = CountVectorizer(stop_words='english',\n",
    "                       decode_error='ignore',\n",
    "                       analyzer=stemmed_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.B. Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = countv.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.C. Create a sparse matrix for scikit-learn\n",
    "\n",
    "Create a dense 2-D ndarray `X` from the sparse matrix. Make a 1-D ndarray `y` (the list of labels you created earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_X.todense()\n",
    "y = df.spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = countv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.DataFrame(X, columns=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2841, 69130), (2841,), (2841, 69130))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Understand and visualize your features\n",
    "\n",
    "Sometimes you may find it difficult to visualize text data. This section provides some exercises that give you insight into how you may modify your text features for improved performance.\n",
    "\n",
    "#### 4.A. Understand sparse matrices and the transform\n",
    "\n",
    "**For email index 1, print(a list of words and counts, sorted by descending count.** Use only the `train_X` sparse matrix along with the `get_feature_names()` method of your vectorizer. The index of each column in `train_X` refers to a word. That word is given by the element at that same index in `get_feature_names()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(46169, 6), (6738, 6), (51111, 6), (26175, 5), (9487, 5)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag = sorted(list(zip(train_X[0].indices, train_X[0].data)),key=lambda x: -x[1])\n",
    "bag[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('localhost', 6), ('2002', 6), ('org', 6), ('com', 5), ('30', 5)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(words[index],count) for index, count in bag][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2002', 6), ('org', 6), ('localhost', 6), ('sep', 5), ('mon', 5)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_ = df.iloc[0].sort_values(ascending=False)\n",
    "bag  = [(word, count) for word, count in zip (bag_.index, bag_.values)]\n",
    "bag[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notice that the most common words in the email are garbage words from the email header! \n",
    "- You can likely improve your model by filtering these in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.B. Using a histogram, visualize the number of emails each word is in.\n",
    "\n",
    "What distribution is it? From this histogram, will most words in your model be noise or signal? Seeing this histogram, what can you likely do to improve your model? (Hint: To quickly graph this, use `np.sum` on the dense matrix `X` of word counts!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 63035)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wpe = np.sum(X,axis=0)\n",
    "wpe[wpe < 12].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.C. Using a histogram, visualize the number of words each email contains.\n",
    "\n",
    "What is the distribution? Are there any outlier emails? Can you find an explanation why there is there likely a spike in the histogram (e.g. are the emails in this dataset of a particular type?) \n",
    "\n",
    "- Plot the distribution of number of words for spam emails on top of the distribution for ham emails! Would this be a useful additional feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(wpe[wpe < 12], bins=20, hist=True, kde=False) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "epw = np.sum(X,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAErVJREFUeJzt3X+MXeV95/H3Zw2BbtLGEAbk2u6abNxtaKSYaJaQZf9gIZsQGtWpFCpoVLypJXcloiXbaBvoP2m0i9RIbdxG2kV1C41T5QcsSRcLsU1ZA6oibUyHxCUQBzENLEzsxZONIclGZWvy3T/uM8nEDJ47M/cy9jPvl3R1z/me59x57pnjzxw/99xzUlVIkvr1j1a7A5Kk8TLoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ07Y7U7AHDeeefVli1bVrsbknRaefjhh79dVROLtTslgn7Lli1MTU2tdjck6bSS5H8N086hG0nqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6twp8c3Y09lnDjy9ovV/7a0/N6KeSNLChj6iT7IuyVeT3NPmL0xyIMkTSe5I8qpWP6vNT7flW8bTdUnSMJYydHMjcGje/MeA3VW1FTgG7Gz1ncCxqnoDsLu1kyStkqGCPskm4JeAP23zAa4A7mpN9gLvadPb2zxt+ZWtvSRpFQx7RP+HwG8DP2zzrwOeq6rjbX4G2NimNwLPALTlz7f2PyHJriRTSaZmZ2eX2X1J0mIWDfok7waOVtXD88sLNK0hlv24ULWnqiaranJiYtHLKUuSlmmYs24uA345ydXA2cDPMDjCX5/kjHbUvgk43NrPAJuBmSRnAK8FvjPynkuShrLoEX1V3VxVm6pqC3AtcH9VvQ94AHhva7YDuLtN72vztOX3V9VLjuglSa+MlXxh6sPAbyWZZjAGf1ur3wa8rtV/C7hpZV2UJK3Ekr4wVVUPAg+26W8ClyzQ5u+Ba0bQN0nSCHgJBEnqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS54a5OfjZSR5K8rdJHkvy0Vb/ZJInkxxsj22tniSfSDKd5JEkbxn3m5Akvbxh7jD1AnBFVX0/yZnAl5L897bsP1TVXSe0fxewtT3eCtzaniVJq2CYm4NXVX2/zZ7ZHie72fd24FNtvS8D65NsWHlXJUnLMdQYfZJ1SQ4CR4H7qupAW3RLG57ZneSsVtsIPDNv9ZlWkyStgqGCvqperKptwCbgkiRvAm4GfgH458C5wIdb8yz0EicWkuxKMpVkanZ2dlmdlyQtbkln3VTVc8CDwFVVdaQNz7wA/BlwSWs2A2yet9om4PACr7WnqiaranJiYmJZnZckLW6Ys24mkqxv0z8FvB34xty4e5IA7wEebavsA65vZ99cCjxfVUfG0ntJ0qKGOetmA7A3yToGfxjurKp7ktyfZILBUM1B4N+29vcCVwPTwA+A94++25KkYS0a9FX1CHDxAvUrXqZ9ATesvGuSpFHwm7GS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4NcyvBs5M8lORvkzyW5KOtfmGSA0meSHJHkle1+lltfrot3zLetyBJOplhjuhfAK6oqjcD24Cr2r1gPwbsrqqtwDFgZ2u/EzhWVW8Adrd2kqRVsmjQ18D32+yZ7VHAFcBdrb6XwQ3CAba3edryK9sNxCVJq2CoMfok65IcBI4C9wF/BzxXVcdbkxlgY5veCDwD0JY/D7xulJ2WJA1vqKCvqherahuwCbgEeONCzdrzQkfvdWIhya4kU0mmZmdnh+2vJGmJlnTWTVU9BzwIXAqsT3JGW7QJONymZ4DNAG35a4HvLPBae6pqsqomJyYmltd7SdKihjnrZiLJ+jb9U8DbgUPAA8B7W7MdwN1tel+bpy2/v6peckQvSXplnLF4EzYAe5OsY/CH4c6quifJ14HPJflPwFeB21r724A/TzLN4Ej+2jH0W5I0pEWDvqoeAS5eoP5NBuP1J9b/HrhmJL2TJK2Y34yVpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzg1zz9jNSR5IcijJY0lubPXfTfKtJAfb4+p569ycZDrJ40neOc43IEk6uWHuGXsc+FBVfSXJTwMPJ7mvLdtdVb8/v3GSixjcJ/YXgZ8F/keSn6+qF0fZcUnScBY9oq+qI1X1lTb9PeAQsPEkq2wHPldVL1TVk8A0C9xbVpL0yljSGH2SLQxuFH6glT6Q5JEktyc5p9U2As/MW22GBf4wJNmVZCrJ1Ozs7JI7LkkazjBDNwAkeQ3weeCDVfXdJLcC/xGo9vwHwG8AWWD1ekmhag+wB2BycvIly6VXymcOPL2i9X/trT83op5I4zHUEX2SMxmE/Ker6gsAVfVsVb1YVT8E/oQfD8/MAJvnrb4JODy6LkuSlmKYs24C3AYcqqqPz6tvmNfsV4BH2/Q+4NokZyW5ENgKPDS6LkuSlmKYoZvLgF8HvpbkYKv9DnBdkm0MhmWeAn4ToKoeS3In8HUGZ+zc4Bk3krR6Fg36qvoSC4+733uSdW4BbllBvyRJI+I3YyWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1Lnhr4EgnSqWuklDKTeeUQvSZ0z6CWpcwa9JHXOMXpphbzMsU51HtFLUucMeknqnEEvSZ0z6CWpcwa9JHVumFsJbk7yQJJDSR5LcmOrn5vkviRPtOdzWj1JPpFkOskjSd4y7jchSXp5wxzRHwc+VFVvBC4FbkhyEXATsL+qtgL72zzAuxjcJ3YrsAu4deS9liQNbZhbCR4BjrTp7yU5BGwEtgOXt2Z7gQeBD7f6p6qqgC8nWZ9kQ3sd6SW8Vo00Xksao0+yBbgYOABcMBfe7fn81mwj8My81WZaTZK0CoYO+iSvAT4PfLCqvnuypgvUaoHX25VkKsnU7OzssN2QJC3RUEGf5EwGIf/pqvpCKz+bZENbvgE42uozwOZ5q28CDp/4mlW1p6omq2pyYmJiuf2XJC1imLNuAtwGHKqqj89btA/Y0aZ3AHfPq1/fzr65FHje8XlJWj3DXNTsMuDXga8lOdhqvwP8HnBnkp3A08A1bdm9wNXANPAD4P0j7bEkaUmGOevmSyw87g5w5QLtC7hhhf2SJI2I34yVpM55PXpplXk9e42bR/SS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXPD3Erw9iRHkzw6r/a7Sb6V5GB7XD1v2c1JppM8nuSd4+q4JGk4wxzRfxK4aoH67qra1h73AiS5CLgW+MW2zn9Jsm5UnZUkLd0wtxL86yRbhny97cDnquoF4Mkk08AlwP9cdg91ylvpjTMkjddK7jD1gSTXA1PAh6rqGLAR+PK8NjOtJmlMvEOVFrPcD2NvBf4psA04AvxBqy90E/Fa6AWS7EoylWRqdnZ2md2QJC1mWUf0VfXs3HSSPwHuabMzwOZ5TTcBh1/mNfYAewAmJycX/GOwFng0JmnclnVEn2TDvNlfAebOyNkHXJvkrCQXAluBh1bWRUnSSix6RJ/ks8DlwHlJZoCPAJcn2cZgWOYp4DcBquqxJHcCXweOAzdU1Yvj6bokaRjDnHVz3QLl207S/hbglpV0SpI0On4zVpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM6t5Obg6sRKb2co6dRm0EtrnPct7t8wtxK8HXg3cLSq3tRq5wJ3AFsY3ErwV6vqWJIAfwRcDfwA+DdV9ZXxdF3g0bikxQ0zRv9J4KoTajcB+6tqK7C/zQO8i8ENwbcCu4BbR9NNSdJyLRr0VfXXwHdOKG8H9rbpvcB75tU/VQNfBtYn2TCqzkqSlm65Z91cUFVHANrz+a2+EXhmXruZVnuJJLuSTCWZmp2dXWY3JEmLGfXplVmgVgs1rKo9VTVZVZMTExMj7oYkac5yz7p5NsmGqjrShmaOtvoMsHleu03A4ZV0UNKpzbN2Tn3LPaLfB+xo0zuAu+fVr8/ApcDzc0M8kqTVMczplZ8FLgfOSzIDfAT4PeDOJDuBp4FrWvN7GZxaOc3g9Mr3j6HPkqQlWDToq+q6l1l05QJtC7hhpZ2SJI2O17qRpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6583BJa0qL3M8fh7RS1LnDHpJ6pxBL0mdM+glqXMr+jA2yVPA94AXgeNVNZnkXOAOYAvwFPCrVXVsZd2UJC3XKI7o/1VVbauqyTZ/E7C/qrYC+9u8JGmVjGPoZjuwt03vBd4zhp8hSRrSSoO+gL9K8nCSXa12QVUdAWjP5y+0YpJdSaaSTM3Ozq6wG5Kkl7PSL0xdVlWHk5wP3JfkG8OuWFV7gD0Ak5OTtcJ+SFqj/MLV4lZ0RF9Vh9vzUeAvgEuAZ5NsAGjPR1faSUnS8i076JO8OslPz00D7wAeBfYBO1qzHcDdK+2kJGn5VjJ0cwHwF0nmXuczVfWXSf4GuDPJTuBp4JqVd1OStFzLDvqq+ibw5gXq/we4ciWdkiSNjlevlLSmrfTD3JV6JT4M9hIIktQ5g16SOmfQS1LnDHpJ6tya/zB2tT+IkaRx84hekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kde60P73S0yMl6eQ8opekzhn0ktQ5g16SOje2oE9yVZLHk0wnuWlcP0eSdHJjCfok64D/DLwLuAi4LslF4/hZkqSTG9cR/SXAdFV9s6r+H/A5YPuYfpYk6STGFfQbgWfmzc+0miTpFTau8+izQK1+okGyC9jVZr+f5PEx9eVUdB7w7dXuxCpzG7gN5qzp7fC+wdNyt8E/GabRuIJ+Btg8b34TcHh+g6raA+wZ088/pSWZqqrJ1e7HanIbuA3muB3Gvw3GNXTzN8DWJBcmeRVwLbBvTD9LknQSYzmir6rjST4AfBFYB9xeVY+N42dJkk5ubNe6qap7gXvH9fqnuTU5ZHUCt4HbYI7bYczbIFW1eCtJ0mnLSyBIUucM+hFLsjnJA0kOJXksyY2tfm6S+5I80Z7PafUk+US7VMQjSd6yuu9gdJKsS/LVJPe0+QuTHGjb4I72QT1Jzmrz0235ltXs9yglWZ/kriTfaPvE29bavpDk37d/C48m+WySs3vfF5LcnuRokkfn1Zb8e0+yo7V/IsmO5fbHoB+948CHquqNwKXADe3yDzcB+6tqK7C/zcPgMhFb22MXcOsr3+WxuRE4NG/+Y8Dutg2OATtbfSdwrKreAOxu7XrxR8BfVtUvAG9msD3WzL6QZCPw74DJqnoTg5MzrqX/feGTwFUn1Jb0e09yLvAR4K0Mrjbwkbk/DktWVT7G+ADuBv418DiwodU2AI+36T8GrpvX/kftTucHg+9O7AeuAO5h8CW6bwNntOVvA77Ypr8IvK1Nn9HaZbXfwwi2wc8AT574XtbSvsCPvyV/bvvd3gO8cy3sC8AW4NHl/t6B64A/nlf/iXZLeXhEP0btv50XAweAC6rqCEB7Pr816/VyEX8I/Dbwwzb/OuC5qjre5ue/zx9tg7b8+db+dPd6YBb4szaE9adJXs0a2heq6lvA7wNPA0cY/G4fZu3tC7D03/vI9geDfkySvAb4PPDBqvruyZouUDutT4VK8m7gaFU9PL+8QNMaYtnp7AzgLcCtVXUx8H/58X/XF9LddmhDDduBC4GfBV7NYKjiRL3vCyfzcu95ZNvCoB+DJGcyCPlPV9UXWvnZJBva8g3A0VZf9HIRp6HLgF9O8hSDK5deweAIf32Sue9uzH+fP9oGbflrge+8kh0ekxlgpqoOtPm7GAT/WtoX3g48WVWzVfUPwBeAf8Ha2xdg6b/3ke0PBv2IJQlwG3Coqj4+b9E+YO5T8x0Mxu7n6te3T94vBZ6f++/d6aqqbq6qTVW1hcEHb/dX1fuAB4D3tmYnboO5bfPe1v60P4qrqv8NPJPkn7XSlcDXWUP7AoMhm0uT/OP2b2NuG6ypfaFZ6u/9i8A7kpzT/mf0jlZbutX+wKK3B/AvGfz36hHgYHtczWCccT/wRHs+t7UPg5u0/B3wNQZnJ6z6+xjh9rgcuKdNvx54CJgG/itwVquf3ean2/LXr3a/R/j+twFTbX/4b8A5a21fAD4KfAN4FPhz4Kze9wXgsww+k/gHBkfmO5fzewd+o22LaeD9y+2P34yVpM45dCNJnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknq3P8HQi2cZIgqSHUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(epw[epw < 1000], hist=True, kde=False) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEu5JREFUeJzt3X+MXeV95/H3p4ZAm2xjCANybbMmiXcbWikGzQJZ9o8sZBNCq5pKYQWJGitryV2JqKTNbgv9J81qkRKpDd1Iu6huoXGq/KIkXSzENssaoip/xHRIXAfiICaBxRO7eLL8SLJR2UK++8d9Jpm6g+fOzL0e+5n3S7q65zznuec+99wzn/vMc8+5J1WFJKlfP7XaDZAkjZdBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SercGavdAIDzzjuvtmzZstrNkKTTyiOPPPLdqppYrN4pEfRbtmxhampqtZshSaeVJP97mHoO3UhS5wx6SeqcQS9JnTPoJalzQwd9knVJvpbkvjZ/UZL9SZ5I8rkkr2rlZ7X56bZ8y3iaLkkaxlJ69DcDh+bNfxS4vaq2As8BO1v5TuC5qnojcHurJ0laJUMFfZJNwC8Bf9LmA1wF3NOq7AGua9Pb2zxt+dWtviRpFQzbo/9D4LeBH7X51wHPV9VLbX4G2NimNwKHAdryF1p9SdIqWDTok/wycKyqHplfvEDVGmLZ/PXuSjKVZGp2dnaoxkqSlm6YM2OvBH4lybXA2cDPMujhr09yRuu1bwKOtPozwGZgJskZwGuBZ49faVXtBnYDTE5OdnOF8k/vf3ok63n35ReOZD2StGiPvqpurapNVbUFuAF4sKreAzwEvKtV2wHc26b3tnna8gerqpsgl6TTzUqOo/8d4LeSTDMYg7+zld8JvK6V/xZwy8qaKElaiSX9qFlVfQn4Upv+NnDZAnX+Drh+BG2TJI2AZ8ZKUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5xYN+iRnJ3k4yd8keSzJh1v5J5I8meRAu21r5Uny8STTSQ4muXTcL0KS9MqGuZTgi8BVVfWDJGcCX07yP9qy/1hV9xxX/53A1na7HLij3UuSVsGiPfoa+EGbPbPd6gQP2Q58sj3uK8D6JBtW3lRJ0nIMNUafZF2SA8Ax4IGq2t8W3daGZ25PclYr2wgcnvfwmVYmSVoFQwV9Vb1cVduATcBlSX4RuBX4eeBfAOcCv9OqZ6FVHF+QZFeSqSRTs7Ozy2q8JGlxSzrqpqqeB74EXFNVR9vwzIvAnwKXtWozwOZ5D9sEHFlgXburarKqJicmJpbVeEnS4oY56mYiyfo2/dPA24Bvzo27JwlwHfBoe8he4L3t6JsrgBeq6uhYWi9JWtQwR91sAPYkWcfgg+HuqrovyYNJJhgM1RwA/n2rfz9wLTAN/BB43+ibLUka1qJBX1UHgUsWKL/qFeoXcNPKmyZJGgXPjJWkzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TODXPN2LOTPJzkb5I8luTDrfyiJPuTPJHkc0le1crPavPTbfmW8b4ESdKJDNOjfxG4qqreDGwDrmkX/f4ocHtVbQWeA3a2+juB56rqjcDtrZ4kaZUsGvQ18IM2e2a7FXAVcE8r3wNc16a3t3na8quTZGQtliQtyVBj9EnWJTkAHAMeAL4FPF9VL7UqM8DGNr0ROAzQlr8AvG6UjZYkDW+ooK+ql6tqG7AJuAx400LV2v1Cvfc6viDJriRTSaZmZ2eHba8kaYmWdNRNVT0PfAm4Alif5Iy2aBNwpE3PAJsB2vLXAs8usK7dVTVZVZMTExPLa70kaVHDHHUzkWR9m/5p4G3AIeAh4F2t2g7g3ja9t83Tlj9YVf+oRy9JOjnOWLwKG4A9SdYx+GC4u6ruS/IN4LNJ/jPwNeDOVv9O4M+STDPoyd8whnZLkoa0aNBX1UHgkgXKv81gvP748r8Drh9J6yRJK+aZsZLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktS5Ya4ZuznJQ0kOJXksyc2t/PeSfCfJgXa7dt5jbk0yneTxJO8Y5wuQJJ3YMNeMfQn4YFV9Nck/AR5J8kBbdntV/f78ykkuZnCd2F8Afg74X0n+WVW9PMqGS6Pw6f1Pj2Q97778wpGsRxqHRXv0VXW0qr7apr8PHAI2nuAh24HPVtWLVfUkMM0C15aVJJ0cSxqjT7KFwYXC97ei9yc5mOSuJOe0so3A4XkPm+HEHwySpDEaOuiTvAb4PPCBqvoecAfwBmAbcBT4g7mqCzy8FljfriRTSaZmZ2eX3HBJ0nCGCvokZzII+U9V1RcAquqZqnq5qn4E/DE/GZ6ZATbPe/gm4Mjx66yq3VU1WVWTExMTK3kNkqQTGOaomwB3Aoeq6mPzyjfMq/arwKNtei9wQ5KzklwEbAUeHl2TJUlLMcxRN1cCvwZ8PcmBVva7wI1JtjEYlnkK+HWAqnosyd3ANxgcsXOTR9xI0upZNOir6sssPO5+/wkecxtw2wraJUkaEc+MlaTOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0b5jh66ZQzql+dlNYCe/SS1DmDXpI6Z9BLUucMeknqnF/GSiMwii+HvRyhxsUevSR1zqCXpM4Z9JLUOYNekjpn0EtS54a5ZuzmJA8lOZTksSQ3t/JzkzyQ5Il2f04rT5KPJ5lOcjDJpeN+EZKkVzZMj/4l4INV9SbgCuCmJBcDtwD7qmorsK/NA7yTwQXBtwK7gDtG3mpJ0tAWDfqqOlpVX23T3wcOARuB7cCeVm0PcF2b3g58sga+AqxPsmHkLZckDWVJY/RJtgCXAPuBC6rqKAw+DIDzW7WNwOF5D5tpZZKkVTB00Cd5DfB54ANV9b0TVV2grBZY364kU0mmZmdnh22GJGmJhgr6JGcyCPlPVdUXWvEzc0My7f5YK58BNs97+CbgyPHrrKrdVTVZVZMTExPLbb8kaRHDHHUT4E7gUFV9bN6ivcCONr0DuHde+Xvb0TdXAC/MDfFIkk6+YX7U7Erg14CvJznQyn4X+Ahwd5KdwNPA9W3Z/cC1wDTwQ+B9I22xJGlJFg36qvoyC4+7A1y9QP0CblphuyRJI+KZsZLUOYNekjrnhUd0Uo3iAh2Slsagl04Ro/oQ9EpVOp5DN5LUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0b5pqxdyU5luTReWW/l+Q7SQ6027Xzlt2aZDrJ40neMa6GS5KGM0yP/hPANQuU315V29rtfoAkFwM3AL/QHvPfkqwbVWMlSUu3aNBX1V8Bzw65vu3AZ6vqxap6ksEFwi9bQfskSSu0kjH69yc52IZ2zmllG4HD8+rMtDJJ0ipZbtDfAbwB2AYcBf6glWeBurXQCpLsSjKVZGp2dnaZzZAkLWZZQV9Vz1TVy1X1I+CP+cnwzAyweV7VTcCRV1jH7qqarKrJiYmJ5TRDkjSEZQV9kg3zZn8VmDsiZy9wQ5KzklwEbAUeXlkTJUkrsejFwZN8BngrcF6SGeBDwFuTbGMwLPMU8OsAVfVYkruBbwAvATdV1cvjabokaRiLBn1V3bhA8Z0nqH8bcNtKGiVJGh3PjJWkzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXOLHkcv6fTy6f1Pj2Q97778wpGsR6vPHr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpc54wdYrypBdJo7Jojz7JXUmOJXl0Xtm5SR5I8kS7P6eVJ8nHk0wnOZjk0nE2XpK0uGGGbj4BXHNc2S3AvqraCuxr8wDvZHBB8K3ALuCO0TRTkrRciwZ9Vf0V8OxxxduBPW16D3DdvPJP1sBXgPVJNoyqsZKkpVvul7EXVNVRgHZ/fivfCByeV2+mlUmSVsmoj7rJAmW1YMVkV5KpJFOzs7MjboYkac5yg/6ZuSGZdn+slc8Am+fV2wQcWWgFVbW7qiaranJiYmKZzZAkLWa5Qb8X2NGmdwD3zit/bzv65grghbkhHknS6lj0OPoknwHeCpyXZAb4EPAR4O4kO4Gngetb9fuBa4Fp4IfA+8bQZq2CUR3XL+nkWzToq+rGV1h09QJ1C7hppY2SJI2OZ8ZKWpBnZ/fD37qRpM4Z9JLUOYNekjrnGH3jUSWSemWPXpI6Z9BLUuccupE0Vh6mufoM+s4t54/sDU//+T8uG0VjhvCtC69fvJKkJXHoRpI6Z9BLUuccujlFLTR8IknLYY9ekjpn0EtS5wx6SeqcQS9JnTPoJalzKzrqJslTwPeBl4GXqmoyybnA54AtwFPAv62q51bWTEnSco2iR/+vq2pbVU22+VuAfVW1FdjX5iVJq2QcQzfbgT1teg9w3RieQ5I0pJUGfQH/M8kjSXa1sguq6ihAuz9/hc8hSVqBlZ4Ze2VVHUlyPvBAkm8O+8D2wbAL4MIL/VU6SRqXFQV9VR1p98eS/AVwGfBMkg1VdTTJBuDYKzx2N7AbYHJyslbSDvVjNX/6wV/OVK+WHfRJXg38VFV9v02/HfhPwF5gB/CRdn/vKBoqaW3zd+2XbyU9+guAv0gyt55PV9VfJvlr4O4kO4GnAbtJkrSKlh30VfVt4M0LlP8f4OqVNEqSNDqeGStJnTPoJalzXnhEajziR70y6CWtKaM6emdUTsZRQAa9tMb5n0z/DHrpFLBWrxHsh8zJ4ZexktQ5g16SOmfQS1LnDHpJ6pxBL0md86gbSWvSWjrixx69JHXutO/Rn2pnuUnSqcYevSR17rTv0Y/TWj1bUVJf7NFLUufGFvRJrknyeJLpJLeM63kkSSc2lqBPsg74r8A7gYuBG5NcPI7nkiSd2Lh69JcB01X17ar6f8Bnge1jei5J0gmMK+g3Aofnzc+0MknSSTauo26yQFn9gwrJLmBXm/1BksfH1JZT0XnAd1e7EavMbeA2mLMGt8N/+PHUewZ3y90G/3SYSuMK+hlg87z5TcCR+RWqajewe0zPf0pLMlVVk6vdjtXkNnAbzHE7jH8bjGvo5q+BrUkuSvIq4AZg75ieS5J0AmPp0VfVS0neD3wRWAfcVVWPjeO5JEknNrYzY6vqfuD+ca3/NLcmh6yO4zZwG8xxO4x5G6SqFq8lSTpt+RMIktQ5g37EkmxO8lCSQ0keS3JzKz83yQNJnmj357TyJPl4+6mIg0kuXd1XMDpJ1iX5WpL72vxFSfa3bfC59kU9Sc5q89Nt+ZbVbPcoJVmf5J4k32z7xFvW2r6Q5Dfb38KjST6T5Oze94UkdyU5luTReWVLft+T7Gj1n0iyY7ntMehH7yXgg1X1JuAK4Kb28w+3APuqaiuwr83D4GcitrbbLuCOk9/ksbkZODRv/qPA7W0bPAfsbOU7geeq6o3A7a1eL/4L8JdV9fPAmxlsjzWzLyTZCPwGMFlVv8jg4Iwb6H9f+ARwzXFlS3rfk5wLfAi4nMGvDXxo7sNhyarK2xhvwL3AvwEeBza0sg3A4236j4Ab59X/cb3T+cbg3Il9wFXAfQxOovsucEZb/hbgi236i8Bb2vQZrV5W+zWMYBv8LPDk8a9lLe0L/OQs+XPbe3sf8I61sC8AW4BHl/u+AzcCfzSv/B/UW8rNHv0YtX87LwH2AxdU1VGAdn9+q9brz0X8IfDbwI/a/OuA56vqpTY//3X+eBu05S+0+qe71wOzwJ+2Iaw/SfJq1tC+UFXfAX4feBo4yuC9fYS1ty/A0t/3ke0PBv2YJHkN8HngA1X1vRNVXaDstD4UKskvA8eq6pH5xQtUrSGWnc7OAC4F7qiqS4D/y0/+XV9Id9uhDTVsBy4Cfg54NYOhiuP1vi+cyCu95pFtC4N+DJKcySDkP1VVX2jFzyTZ0JZvAI618kV/LuI0dCXwK0meYvDLpVcx6OGvTzJ37sb81/njbdCWvxZ49mQ2eExmgJmq2t/m72EQ/GtpX3gb8GRVzVbV3wNfAP4la29fgKW/7yPbHwz6EUsS4E7gUFV9bN6ivcDct+Y7GIzdz5W/t33zfgXwwty/d6erqrq1qjZV1RYGX7w9WFXvAR4C3tWqHb8N5rbNu1r9074XV1V/CxxO8s9b0dXAN1hD+wKDIZsrkvxM+9uY2wZral9olvq+fxF4e5Jz2n9Gb29lS7faX1j0dgP+FYN/rw4CB9rtWgbjjPuAJ9r9ua1+GFyk5VvA1xkcnbDqr2OE2+OtwH1t+vXAw8A08OfAWa387DY/3Za/frXbPcLXvw2YavvDfwfOWWv7AvBh4JvAo8CfAWf1vi8An2HwncTfM+iZ71zO+w78u7YtpoH3Lbc9nhkrSZ1z6EaSOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUuf8P4eiw3qYt+RoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(epw[(y == \"0\")&[x[0] for x in (epw < 1000).tolist()] ], hist=True, kde=False) ;\n",
    "sns.distplot(epw[(y == \"1\")&[x[0] for x in (epw < 1000).tolist()] ], hist=True, kde=False) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Estimate generalization accuracy\n",
    "\n",
    "Use `cross_val_score` with the models `BernoulliNB` and `MultinomialNB` to assess how well these models classify emails. Can you guess why one may perform better than the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "berno = BernoulliNB()\n",
    "multy = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9208061163963537, 0.9813429569584837)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(berno, X, y, cv=5).mean(), cross_val_score(multy, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Confusion matrix and Classification report\n",
    "\n",
    "Recall that to make a confusion matrix, we will need a specific split. So, use `test_train_split`, manually fit the model using the best performer, then find the confusion matrix and classificaation report (in the `metrics` package). Is your model worse at Type I or Type II errors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9704641350210971"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multy.fit(X_train, y_train)\n",
    "multy.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[589,   1],\n",
       "       [ 20, 101]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, multy.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       590\n",
      "           1       0.99      0.83      0.91       121\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       711\n",
      "   macro avg       0.98      0.92      0.94       711\n",
      "weighted avg       0.97      0.97      0.97       711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, multy.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model on the hard_ham\n",
    "\n",
    "Does it perform as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, (231, 69130), (2130, 69130))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_ham = countv.transform(hard_ham_text)\n",
    "Xhard = hard_ham.todense()\n",
    "yhard = [0 for _ in range(len(Xhard))]\n",
    "\n",
    "len(yhard), Xhard.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:182: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multy.score(Xhard, yhard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = multy.predict(Xhard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 79, 152],\n",
       "       [  0,   0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(yhard, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.34      0.51       231\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.34      0.34      0.34       231\n",
      "   macro avg       0.50      0.17      0.25       231\n",
      "weighted avg       1.00      0.34      0.51       231\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yhard, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Improve your model by looking at mispredictions\n",
    "\n",
    "print(the most common words in your false positives of the hard hams versus the spams. (Perhaps write a function of step 4A. Consider using a `collections.Counter` to combine the counts!) Does comparing the most frequent words in the hard ham to those in the spam give you some ideas for how to distinguish between them? What extra features might you add to your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(180, 25),\n",
       " (178, 17),\n",
       " (179, 17),\n",
       " (186, 15),\n",
       " (182, 15),\n",
       " (187, 15),\n",
       " (175, 14),\n",
       " (181, 14),\n",
       " (202, 13),\n",
       " (176, 12),\n",
       " (172, 12),\n",
       " (173, 12),\n",
       " (171, 11),\n",
       " (177, 11),\n",
       " (191, 11),\n",
       " (528, 11),\n",
       " (206, 11),\n",
       " (444, 10),\n",
       " (183, 10),\n",
       " (174, 10),\n",
       " (588, 10),\n",
       " (195, 10),\n",
       " (478, 10),\n",
       " (200, 9),\n",
       " (511, 9),\n",
       " (235, 9),\n",
       " (556, 9),\n",
       " (565, 9),\n",
       " (201, 9),\n",
       " (169, 9),\n",
       " (188, 8),\n",
       " (431, 8),\n",
       " (486, 8),\n",
       " (572, 8),\n",
       " (585, 8),\n",
       " (612, 8),\n",
       " (495, 8),\n",
       " (441, 8),\n",
       " (623, 8),\n",
       " (489, 8),\n",
       " (210, 8),\n",
       " (625, 8),\n",
       " (196, 8),\n",
       " (563, 8),\n",
       " (189, 8),\n",
       " (488, 8),\n",
       " (427, 8),\n",
       " (610, 8),\n",
       " (515, 7),\n",
       " (236, 7),\n",
       " (497, 7),\n",
       " (558, 7),\n",
       " (595, 7),\n",
       " (469, 7),\n",
       " (479, 7),\n",
       " (451, 7),\n",
       " (190, 7),\n",
       " (554, 7),\n",
       " (517, 7),\n",
       " (538, 7),\n",
       " (216, 7),\n",
       " (510, 7),\n",
       " (575, 7),\n",
       " (442, 7),\n",
       " (522, 7),\n",
       " (698, 7),\n",
       " (192, 7),\n",
       " (184, 7),\n",
       " (519, 7),\n",
       " (701, 7),\n",
       " (618, 7),\n",
       " (512, 7),\n",
       " (560, 7),\n",
       " (241, 7),\n",
       " (516, 7),\n",
       " (403, 7),\n",
       " (432, 7),\n",
       " (552, 7),\n",
       " (421, 7),\n",
       " (571, 7),\n",
       " (643, 7),\n",
       " (198, 7),\n",
       " (410, 7),\n",
       " (379, 6),\n",
       " (669, 6),\n",
       " (692, 6),\n",
       " (542, 6),\n",
       " (405, 6),\n",
       " (681, 6),\n",
       " (587, 6),\n",
       " (199, 6),\n",
       " (582, 6),\n",
       " (548, 6),\n",
       " (544, 6),\n",
       " (518, 6),\n",
       " (540, 6),\n",
       " (546, 6),\n",
       " (786, 6),\n",
       " (514, 6),\n",
       " (185, 6),\n",
       " (167, 6),\n",
       " (509, 6),\n",
       " (580, 6),\n",
       " (541, 6),\n",
       " (464, 6),\n",
       " (629, 6),\n",
       " (475, 6),\n",
       " (380, 6),\n",
       " (660, 6),\n",
       " (424, 6),\n",
       " (665, 6),\n",
       " (492, 6),\n",
       " (536, 6),\n",
       " (601, 6),\n",
       " (399, 6),\n",
       " (617, 6),\n",
       " (496, 6),\n",
       " (527, 6),\n",
       " (551, 6),\n",
       " (459, 6),\n",
       " (460, 6),\n",
       " (628, 6),\n",
       " (452, 6),\n",
       " (631, 5),\n",
       " (462, 5),\n",
       " (443, 5),\n",
       " (696, 5),\n",
       " (656, 5),\n",
       " (491, 5),\n",
       " (667, 5),\n",
       " (269, 5),\n",
       " (584, 5),\n",
       " (213, 5),\n",
       " (407, 5),\n",
       " (456, 5),\n",
       " (500, 5),\n",
       " (673, 5),\n",
       " (482, 5),\n",
       " (212, 5),\n",
       " (461, 5),\n",
       " (458, 5),\n",
       " (290, 5),\n",
       " (484, 5),\n",
       " (604, 5),\n",
       " (445, 5),\n",
       " (209, 5),\n",
       " (621, 5),\n",
       " (335, 5),\n",
       " (566, 5),\n",
       " (237, 5),\n",
       " (639, 5),\n",
       " (386, 5),\n",
       " (385, 5),\n",
       " (648, 5),\n",
       " (215, 5),\n",
       " (323, 5),\n",
       " (476, 5),\n",
       " (579, 5),\n",
       " (529, 5),\n",
       " (220, 5),\n",
       " (242, 5),\n",
       " (819, 5),\n",
       " (649, 5),\n",
       " (411, 5),\n",
       " (603, 5),\n",
       " (693, 5),\n",
       " (611, 5),\n",
       " (549, 5),\n",
       " (561, 5),\n",
       " (499, 5),\n",
       " (428, 5),\n",
       " (204, 5),\n",
       " (641, 5),\n",
       " (395, 5),\n",
       " (680, 5),\n",
       " (734, 5),\n",
       " (468, 5),\n",
       " (203, 5),\n",
       " (501, 5),\n",
       " (435, 5),\n",
       " (530, 5),\n",
       " (609, 5),\n",
       " (539, 5),\n",
       " (532, 5),\n",
       " (637, 5),\n",
       " (408, 5),\n",
       " (368, 5),\n",
       " (494, 5),\n",
       " (534, 5),\n",
       " (388, 5),\n",
       " (324, 5),\n",
       " (841, 5),\n",
       " (761, 4),\n",
       " (766, 4),\n",
       " (423, 4),\n",
       " (642, 4),\n",
       " (250, 4),\n",
       " (415, 4),\n",
       " (470, 4),\n",
       " (455, 4),\n",
       " (244, 4),\n",
       " (874, 4),\n",
       " (666, 4),\n",
       " (636, 4),\n",
       " (240, 4),\n",
       " (525, 4),\n",
       " (325, 4),\n",
       " (508, 4),\n",
       " (355, 4),\n",
       " (596, 4),\n",
       " (243, 4),\n",
       " (684, 4),\n",
       " (214, 4),\n",
       " (651, 4),\n",
       " (295, 4),\n",
       " (472, 4),\n",
       " (823, 4),\n",
       " (347, 4),\n",
       " (657, 4),\n",
       " (343, 4),\n",
       " (288, 4),\n",
       " (653, 4),\n",
       " (218, 4),\n",
       " (576, 4),\n",
       " (387, 4),\n",
       " (454, 4),\n",
       " (712, 4),\n",
       " (426, 4),\n",
       " (737, 4),\n",
       " (568, 4),\n",
       " (193, 4),\n",
       " (913, 4),\n",
       " (311, 4),\n",
       " (790, 4),\n",
       " (725, 4),\n",
       " (437, 4),\n",
       " (770, 4),\n",
       " (360, 4),\n",
       " (620, 4),\n",
       " (285, 4),\n",
       " (166, 4),\n",
       " (382, 4),\n",
       " (485, 4),\n",
       " (256, 4),\n",
       " (553, 4),\n",
       " (448, 4),\n",
       " (727, 4),\n",
       " (457, 4),\n",
       " (729, 4),\n",
       " (594, 4),\n",
       " (820, 4),\n",
       " (1536, 4),\n",
       " (817, 4),\n",
       " (317, 4),\n",
       " (390, 4),\n",
       " (465, 4),\n",
       " (779, 4),\n",
       " (487, 4),\n",
       " (268, 4),\n",
       " (450, 4),\n",
       " (533, 4),\n",
       " (523, 4),\n",
       " (292, 4),\n",
       " (205, 4),\n",
       " (301, 4),\n",
       " (574, 4),\n",
       " (778, 4),\n",
       " (316, 4),\n",
       " (506, 4),\n",
       " (315, 4),\n",
       " (600, 4),\n",
       " (614, 4),\n",
       " (583, 4),\n",
       " (364, 4),\n",
       " (413, 4),\n",
       " (350, 4),\n",
       " (741, 4),\n",
       " (406, 4),\n",
       " (589, 4),\n",
       " (466, 4),\n",
       " (294, 4),\n",
       " (638, 3),\n",
       " (480, 3),\n",
       " (787, 3),\n",
       " (419, 3),\n",
       " (842, 3),\n",
       " (513, 3),\n",
       " (434, 3),\n",
       " (463, 3),\n",
       " (264, 3),\n",
       " (751, 3),\n",
       " (375, 3),\n",
       " (291, 3),\n",
       " (498, 3),\n",
       " (646, 3),\n",
       " (409, 3),\n",
       " (221, 3),\n",
       " (425, 3),\n",
       " (785, 3),\n",
       " (284, 3),\n",
       " (613, 3),\n",
       " (332, 3),\n",
       " (795, 3),\n",
       " (682, 3),\n",
       " (722, 3),\n",
       " (731, 3),\n",
       " (420, 3),\n",
       " (526, 3),\n",
       " (726, 3),\n",
       " (396, 3),\n",
       " (676, 3),\n",
       " (805, 3),\n",
       " (578, 3),\n",
       " (412, 3),\n",
       " (194, 3),\n",
       " (694, 3),\n",
       " (615, 3),\n",
       " (547, 3),\n",
       " (702, 3),\n",
       " (493, 3),\n",
       " (752, 3),\n",
       " (763, 3),\n",
       " (721, 3),\n",
       " (728, 3),\n",
       " (384, 3),\n",
       " (222, 3),\n",
       " (714, 3),\n",
       " (383, 3),\n",
       " (230, 3),\n",
       " (887, 3),\n",
       " (276, 3),\n",
       " (768, 3),\n",
       " (331, 3),\n",
       " (490, 3),\n",
       " (247, 3),\n",
       " (800, 3),\n",
       " (862, 3),\n",
       " (713, 3),\n",
       " (799, 3),\n",
       " (608, 3),\n",
       " (267, 3),\n",
       " (227, 3),\n",
       " (255, 3),\n",
       " (392, 3),\n",
       " (624, 3),\n",
       " (650, 3),\n",
       " (545, 3),\n",
       " (663, 3),\n",
       " (597, 3),\n",
       " (745, 3),\n",
       " (165, 3),\n",
       " (535, 3),\n",
       " (744, 3),\n",
       " (707, 3),\n",
       " (266, 3),\n",
       " (318, 3),\n",
       " (239, 3),\n",
       " (381, 3),\n",
       " (746, 3),\n",
       " (271, 3),\n",
       " (716, 3),\n",
       " (719, 3),\n",
       " (404, 3),\n",
       " (555, 3),\n",
       " (259, 3),\n",
       " (562, 3),\n",
       " (170, 3),\n",
       " (89, 3),\n",
       " (418, 3),\n",
       " (825, 3),\n",
       " (557, 3),\n",
       " (797, 3),\n",
       " (658, 3),\n",
       " (633, 3),\n",
       " (524, 3),\n",
       " (430, 3),\n",
       " (474, 3),\n",
       " (365, 3),\n",
       " (591, 3),\n",
       " (197, 3),\n",
       " (706, 3),\n",
       " (219, 3),\n",
       " (310, 3),\n",
       " (260, 3),\n",
       " (246, 3),\n",
       " (570, 3),\n",
       " (520, 3),\n",
       " (602, 3),\n",
       " (377, 3),\n",
       " (606, 3),\n",
       " (503, 3),\n",
       " (569, 3),\n",
       " (481, 3),\n",
       " (438, 3),\n",
       " (122, 3),\n",
       " (505, 3),\n",
       " (784, 3),\n",
       " (397, 3),\n",
       " (807, 3),\n",
       " (697, 3),\n",
       " (567, 3),\n",
       " (471, 3),\n",
       " (327, 3),\n",
       " (882, 3),\n",
       " (664, 3),\n",
       " (402, 3),\n",
       " (282, 3),\n",
       " (616, 3),\n",
       " (168, 3),\n",
       " (907, 3),\n",
       " (788, 3),\n",
       " (839, 3),\n",
       " (417, 3),\n",
       " (1026, 3),\n",
       " (238, 3),\n",
       " (647, 3),\n",
       " (272, 3),\n",
       " (888, 3),\n",
       " (376, 3),\n",
       " (670, 3),\n",
       " (422, 3),\n",
       " (599, 3),\n",
       " (592, 3),\n",
       " (344, 3),\n",
       " (280, 3),\n",
       " (308, 3),\n",
       " (319, 3),\n",
       " (353, 3),\n",
       " (975, 2),\n",
       " (1187, 2),\n",
       " (231, 2),\n",
       " (429, 2),\n",
       " (354, 2),\n",
       " (467, 2),\n",
       " (367, 2),\n",
       " (893, 2),\n",
       " (732, 2),\n",
       " (917, 2),\n",
       " (884, 2),\n",
       " (686, 2),\n",
       " (962, 2),\n",
       " (374, 2),\n",
       " (1071, 2),\n",
       " (1030, 2),\n",
       " (352, 2),\n",
       " (849, 2),\n",
       " (416, 2),\n",
       " (211, 2),\n",
       " (969, 2),\n",
       " (483, 2),\n",
       " (273, 2),\n",
       " (293, 2),\n",
       " (440, 2),\n",
       " (1121, 2),\n",
       " (400, 2),\n",
       " (914, 2),\n",
       " (254, 2),\n",
       " (149, 2),\n",
       " (223, 2),\n",
       " (164, 2),\n",
       " (373, 2),\n",
       " (322, 2),\n",
       " (757, 2),\n",
       " (652, 2),\n",
       " (446, 2),\n",
       " (106, 2),\n",
       " (313, 2),\n",
       " (848, 2),\n",
       " (607, 2),\n",
       " (699, 2),\n",
       " (361, 2),\n",
       " (956, 2),\n",
       " (531, 2),\n",
       " (932, 2),\n",
       " (877, 2),\n",
       " (644, 2),\n",
       " (677, 2),\n",
       " (348, 2),\n",
       " (228, 2),\n",
       " (229, 2),\n",
       " (261, 2),\n",
       " (672, 2),\n",
       " (863, 2),\n",
       " (207, 2),\n",
       " (735, 2),\n",
       " (904, 2),\n",
       " (537, 2),\n",
       " (107, 2),\n",
       " (1145, 2),\n",
       " (233, 2),\n",
       " (1142, 2),\n",
       " (1617, 2),\n",
       " (398, 2),\n",
       " (792, 2),\n",
       " (619, 2),\n",
       " (709, 2),\n",
       " (328, 2),\n",
       " (356, 2),\n",
       " (436, 2),\n",
       " (366, 2),\n",
       " (773, 2),\n",
       " (590, 2),\n",
       " (297, 2),\n",
       " (834, 2),\n",
       " (954, 2),\n",
       " (372, 2),\n",
       " (371, 2),\n",
       " (564, 2),\n",
       " (977, 2),\n",
       " (630, 2),\n",
       " (708, 2),\n",
       " (253, 2),\n",
       " (314, 2),\n",
       " (775, 2),\n",
       " (958, 2),\n",
       " (151, 2),\n",
       " (1279, 2),\n",
       " (961, 2),\n",
       " (286, 2),\n",
       " (683, 2),\n",
       " (691, 2),\n",
       " (1181, 2),\n",
       " (401, 2),\n",
       " (521, 2),\n",
       " (543, 2),\n",
       " (831, 2),\n",
       " (769, 2),\n",
       " (892, 2),\n",
       " (1021, 2),\n",
       " (705, 2),\n",
       " (700, 2),\n",
       " (453, 2),\n",
       " (507, 2),\n",
       " (645, 2),\n",
       " (225, 2),\n",
       " (767, 2),\n",
       " (678, 2),\n",
       " (858, 2),\n",
       " (771, 2),\n",
       " (593, 2),\n",
       " (885, 2),\n",
       " (659, 2),\n",
       " (897, 2),\n",
       " (655, 2),\n",
       " (965, 2),\n",
       " (733, 2),\n",
       " (504, 2),\n",
       " (717, 2),\n",
       " (634, 2),\n",
       " (781, 2),\n",
       " (704, 2),\n",
       " (370, 2),\n",
       " (935, 2),\n",
       " (359, 2),\n",
       " (559, 2),\n",
       " (1112, 2),\n",
       " (791, 2),\n",
       " (1035, 2),\n",
       " (840, 2),\n",
       " (296, 2),\n",
       " (635, 2),\n",
       " (662, 2),\n",
       " (362, 2),\n",
       " (687, 2),\n",
       " (598, 2),\n",
       " (339, 2),\n",
       " (393, 2),\n",
       " (439, 2),\n",
       " (300, 2),\n",
       " (449, 2),\n",
       " (835, 2),\n",
       " (321, 2),\n",
       " (689, 2),\n",
       " (718, 2),\n",
       " (1029, 2),\n",
       " (577, 2),\n",
       " (988, 2),\n",
       " (1250, 2),\n",
       " (1025, 2),\n",
       " (249, 2),\n",
       " (739, 2),\n",
       " (275, 2),\n",
       " (711, 2),\n",
       " (736, 2),\n",
       " (905, 2),\n",
       " (710, 2),\n",
       " (903, 2),\n",
       " (1009, 2),\n",
       " (1955, 2),\n",
       " (981, 2),\n",
       " (274, 2),\n",
       " (872, 2),\n",
       " (329, 2),\n",
       " (277, 2),\n",
       " (338, 2),\n",
       " (1613, 2),\n",
       " (974, 2),\n",
       " (1067, 2),\n",
       " (3014, 2),\n",
       " (1130, 2),\n",
       " (1233, 1),\n",
       " (1048, 1),\n",
       " (1735, 1),\n",
       " (147, 1),\n",
       " (155, 1),\n",
       " (283, 1),\n",
       " (1055, 1),\n",
       " (137, 1),\n",
       " (326, 1),\n",
       " (844, 1),\n",
       " (818, 1),\n",
       " (902, 1),\n",
       " (949, 1),\n",
       " (939, 1),\n",
       " (391, 1),\n",
       " (3259, 1),\n",
       " (136, 1),\n",
       " (838, 1),\n",
       " (806, 1),\n",
       " (983, 1),\n",
       " (720, 1),\n",
       " (124, 1),\n",
       " (878, 1),\n",
       " (955, 1),\n",
       " (158, 1),\n",
       " (1284, 1),\n",
       " (13311, 1),\n",
       " (671, 1),\n",
       " (145, 1),\n",
       " (138, 1),\n",
       " (896, 1),\n",
       " (1005, 1),\n",
       " (811, 1),\n",
       " (925, 1),\n",
       " (843, 1),\n",
       " (1578, 1),\n",
       " (743, 1),\n",
       " (742, 1),\n",
       " (6258, 1),\n",
       " (2141, 1),\n",
       " (703, 1),\n",
       " (921, 1),\n",
       " (150, 1),\n",
       " (270, 1),\n",
       " (74, 1),\n",
       " (121, 1),\n",
       " (129, 1),\n",
       " (1222, 1),\n",
       " (789, 1),\n",
       " (715, 1),\n",
       " (815, 1),\n",
       " (473, 1),\n",
       " (289, 1),\n",
       " (1297, 1),\n",
       " (159, 1),\n",
       " (951, 1),\n",
       " (860, 1),\n",
       " (1192, 1),\n",
       " (1587, 1),\n",
       " (938, 1),\n",
       " (1235, 1),\n",
       " (13247, 1),\n",
       " (157, 1),\n",
       " (879, 1),\n",
       " (776, 1),\n",
       " (3237, 1),\n",
       " (2970, 1),\n",
       " (1370, 1),\n",
       " (1003, 1),\n",
       " (2383, 1),\n",
       " (1248, 1),\n",
       " (605, 1),\n",
       " (748, 1),\n",
       " (861, 1),\n",
       " (1394, 1),\n",
       " (674, 1),\n",
       " (661, 1),\n",
       " (915, 1),\n",
       " (2442, 1),\n",
       " (2384, 1),\n",
       " (1137, 1),\n",
       " (573, 1),\n",
       " (378, 1),\n",
       " (1491, 1),\n",
       " (1329, 1),\n",
       " (550, 1),\n",
       " (866, 1),\n",
       " (163, 1),\n",
       " (627, 1),\n",
       " (140, 1),\n",
       " (626, 1),\n",
       " (906, 1),\n",
       " (1662, 1),\n",
       " (1257, 1),\n",
       " (1219, 1),\n",
       " (1210, 1),\n",
       " (63, 1),\n",
       " (208, 1),\n",
       " (2540, 1),\n",
       " (1018, 1),\n",
       " (477, 1),\n",
       " (127, 1),\n",
       " (826, 1),\n",
       " (1011, 1),\n",
       " (1591, 1),\n",
       " (1848, 1),\n",
       " (302, 1),\n",
       " (1855, 1),\n",
       " (1886, 1),\n",
       " (829, 1),\n",
       " (782, 1),\n",
       " (1152, 1),\n",
       " (931, 1),\n",
       " (2192, 1),\n",
       " (777, 1),\n",
       " (1073, 1),\n",
       " (724, 1),\n",
       " (162, 1),\n",
       " (1276, 1),\n",
       " (217, 1),\n",
       " (1272, 1),\n",
       " (278, 1),\n",
       " (309, 1),\n",
       " (857, 1),\n",
       " (1223, 1),\n",
       " (502, 1),\n",
       " (1403, 1),\n",
       " (1151, 1),\n",
       " (1558, 1),\n",
       " (1165, 1),\n",
       " (883, 1),\n",
       " (803, 1),\n",
       " (970, 1),\n",
       " (1679, 1),\n",
       " (754, 1),\n",
       " (1561, 1),\n",
       " (774, 1),\n",
       " (814, 1),\n",
       " (248, 1),\n",
       " (92, 1),\n",
       " (2346, 1),\n",
       " (986, 1),\n",
       " (690, 1),\n",
       " (1180, 1),\n",
       " (1292, 1),\n",
       " (1082, 1),\n",
       " (936, 1),\n",
       " (640, 1),\n",
       " (870, 1),\n",
       " (581, 1),\n",
       " (1398, 1),\n",
       " (758, 1),\n",
       " (1643, 1),\n",
       " (258, 1),\n",
       " (433, 1),\n",
       " (808, 1),\n",
       " (1332, 1),\n",
       " (141, 1),\n",
       " (305, 1),\n",
       " (148, 1),\n",
       " (142, 1),\n",
       " (886, 1),\n",
       " (161, 1),\n",
       " (1047, 1),\n",
       " (762, 1),\n",
       " (1033, 1),\n",
       " (964, 1),\n",
       " (123, 1),\n",
       " (1213, 1),\n",
       " (1784, 1),\n",
       " (1470, 1),\n",
       " (793, 1),\n",
       " (1031, 1),\n",
       " (855, 1),\n",
       " (864, 1),\n",
       " (87, 1),\n",
       " (3149, 1),\n",
       " (3257, 1),\n",
       " (226, 1),\n",
       " (723, 1),\n",
       " (1044, 1),\n",
       " (959, 1),\n",
       " (853, 1),\n",
       " (1149, 1),\n",
       " (688, 1),\n",
       " (82, 1),\n",
       " (798, 1),\n",
       " (912, 1),\n",
       " (1294, 1),\n",
       " (262, 1),\n",
       " (363, 1),\n",
       " (5876, 1),\n",
       " (6055, 1),\n",
       " (928, 1),\n",
       " (447, 1),\n",
       " (1412, 1),\n",
       " (2057, 1),\n",
       " (1146, 1),\n",
       " (1004, 1),\n",
       " (1070, 1),\n",
       " (307, 1),\n",
       " (632, 1),\n",
       " (1424, 1),\n",
       " (1333, 1),\n",
       " (947, 1),\n",
       " (759, 1),\n",
       " (847, 1),\n",
       " (1355, 1),\n",
       " (854, 1),\n",
       " (946, 1),\n",
       " (997, 1),\n",
       " (679, 1),\n",
       " (930, 1),\n",
       " (7349, 1),\n",
       " (160, 1),\n",
       " (257, 1),\n",
       " (77, 1),\n",
       " (916, 1),\n",
       " (1119, 1),\n",
       " (586, 1),\n",
       " (337, 1),\n",
       " (1290, 1),\n",
       " (832, 1),\n",
       " (968, 1),\n",
       " (984, 1),\n",
       " (1601, 1),\n",
       " (1387, 1),\n",
       " (2739, 1),\n",
       " (1976, 1),\n",
       " (753, 1),\n",
       " (976, 1),\n",
       " (929, 1),\n",
       " (980, 1),\n",
       " (685, 1),\n",
       " (654, 1),\n",
       " (1208, 1),\n",
       " (3128, 1),\n",
       " (110, 1),\n",
       " (108, 1),\n",
       " (1024, 1),\n",
       " (996, 1),\n",
       " (1188, 1),\n",
       " (1425, 1),\n",
       " (755, 1),\n",
       " (1881, 1),\n",
       " (1853, 1),\n",
       " (1201, 1),\n",
       " (1606, 1),\n",
       " (1600, 1),\n",
       " (1237, 1),\n",
       " (3722, 1),\n",
       " (1460, 1),\n",
       " (312, 1),\n",
       " (1215, 1),\n",
       " (4093, 1),\n",
       " (342, 1),\n",
       " (1341, 1),\n",
       " (1539, 1),\n",
       " (1063, 1),\n",
       " (1209, 1),\n",
       " (827, 1),\n",
       " (772, 1),\n",
       " (695, 1),\n",
       " (232, 1),\n",
       " (394, 1),\n",
       " (1476, 1),\n",
       " (1419, 1),\n",
       " (414, 1),\n",
       " (1107, 1),\n",
       " (306, 1),\n",
       " (1202, 1),\n",
       " (287, 1),\n",
       " (1765, 1),\n",
       " (2113, 1),\n",
       " (833, 1),\n",
       " (1639, 1),\n",
       " (1101, 1),\n",
       " (1993, 1),\n",
       " (131, 1),\n",
       " (4226, 1),\n",
       " (1353, 1),\n",
       " (1461, 1),\n",
       " (1455, 1),\n",
       " (1879, 1),\n",
       " (1712, 1),\n",
       " (2470, 1),\n",
       " (1954, 1),\n",
       " (1012, 1),\n",
       " (303, 1),\n",
       " (810, 1),\n",
       " (3267, 1),\n",
       " (1348, 1),\n",
       " (1027, 1),\n",
       " (1197, 1),\n",
       " (2911, 1),\n",
       " (1759, 1),\n",
       " (1064, 1),\n",
       " (351, 1),\n",
       " (389, 1),\n",
       " (1769, 1),\n",
       " (1102, 1),\n",
       " (1919, 1),\n",
       " (894, 1),\n",
       " (2378, 1),\n",
       " (749, 1),\n",
       " (1139, 1),\n",
       " (7439, 1),\n",
       " (2254, 1),\n",
       " (1690, 1),\n",
       " (1992, 1),\n",
       " (2833, 1),\n",
       " (340, 1),\n",
       " (1599, 1),\n",
       " (320, 1),\n",
       " (2939, 1),\n",
       " (1059, 1),\n",
       " (926, 1),\n",
       " (2086, 1),\n",
       " (1199, 1),\n",
       " (1381, 1),\n",
       " (1113, 1),\n",
       " (4221, 1),\n",
       " (2757, 1),\n",
       " (334, 1),\n",
       " (346, 1),\n",
       " (783, 1),\n",
       " (11445, 1),\n",
       " (1667, 1),\n",
       " (1477, 1),\n",
       " (1450, 1),\n",
       " (1860, 1),\n",
       " (2621, 1),\n",
       " (2969, 1),\n",
       " (3649, 1),\n",
       " (987, 1),\n",
       " (1452, 1),\n",
       " (1046, 1),\n",
       " (2386, 1),\n",
       " (1032, 1),\n",
       " (1326, 1),\n",
       " (1838, 1),\n",
       " (5073, 1),\n",
       " (1061, 1),\n",
       " (1774, 1),\n",
       " (1161, 1),\n",
       " (1189, 1),\n",
       " (3560, 1),\n",
       " (4166, 1),\n",
       " (3298, 1),\n",
       " (760, 1),\n",
       " (1995, 1),\n",
       " (1242, 1),\n",
       " (1361, 1),\n",
       " (952, 1),\n",
       " (2562, 1),\n",
       " (1221, 1),\n",
       " (330, 1),\n",
       " (1134, 1),\n",
       " (341, 1),\n",
       " (1360, 1),\n",
       " (837, 1),\n",
       " (1006, 1),\n",
       " (1097, 1),\n",
       " (2387, 1),\n",
       " (1000, 1),\n",
       " (299, 1),\n",
       " (920, 1)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter(np.sum(train_X.toarray(), axis=1))\n",
    "counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000007070213', '00000254', '00000254', '000001c266a5', '000001c266a5']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[words[c[1]] for c in counter.most_common(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extensions\n",
    "\n",
    "- Can you improve the score on the hard ham?\n",
    "- Try to improve your model by changing or tweaking the model type. (e.g. LogisticRegression/RandomForests) Why do bigrams result in a lower accuracy? (Because nearly all of them are single-email, so they actually add MORE noise!)\n",
    "- Remove features from your model, e.g. junk words.\n",
    "- Add additional features to your model. Can you specifically come up with ideas that might detect spam vs. ham? For example, does an email have an unsubscribe link?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
